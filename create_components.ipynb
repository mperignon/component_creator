{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, glob, string, shutil, re\n",
    "import yaml, json\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "\n",
    "class UnsortableList(list):\n",
    "    def sort(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "class UnsortableOrderedDict(OrderedDict):\n",
    "    def items(self, *args, **kwargs):\n",
    "        return UnsortableList(OrderedDict.items(self, *args, **kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OrderedDictYAMLLoader(yaml.Loader):\n",
    "    \"\"\"\n",
    "    A YAML loader that loads mappings into ordered dictionaries.\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        yaml.Loader.__init__(self, *args, **kwargs)\n",
    " \n",
    "        self.add_constructor(u'tag:yaml.org,2002:map', type(self).construct_yaml_map)\n",
    "        self.add_constructor(u'tag:yaml.org,2002:omap', type(self).construct_yaml_map)\n",
    " \n",
    "    def construct_yaml_map(self, node):\n",
    "        data = OrderedDict()\n",
    "        yield data\n",
    "        value = self.construct_mapping(node)\n",
    "        data.update(value)\n",
    " \n",
    "    def construct_mapping(self, node, deep=False):\n",
    "        if isinstance(node, yaml.MappingNode):\n",
    "            self.flatten_mapping(node)\n",
    "        else:\n",
    "            raise yaml.constructor.ConstructorError(None, None,\n",
    "                'expected a mapping node, but found %s' % node.id, node.start_mark)\n",
    " \n",
    "        mapping = OrderedDict()\n",
    "        for key_node, value_node in node.value:\n",
    "            key = self.construct_object(key_node, deep=deep)\n",
    "            try:\n",
    "                hash(key)\n",
    "            except TypeError, exc:\n",
    "                raise yaml.constructor.ConstructorError('while constructing a mapping',\n",
    "                    node.start_mark, 'found unacceptable key (%s)' % exc, key_node.start_mark)\n",
    "            value = self.construct_object(value_node, deep=deep)\n",
    "            mapping[key] = value\n",
    "        return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def yaml_to_json(comp_dir):\n",
    "    \n",
    "#     inFile = comp_dir + '/db/parameters.yaml'\n",
    "#     outFile = comp_dir + '/db/parameters.json'\n",
    "\n",
    "#     with open(inFile) as f:\n",
    "#         yaml_in = yaml.load(f,OrderedDictYAMLLoader)\n",
    "#         json_out = open(outFile,'w')\n",
    "\n",
    "#         json.dump(yaml_in, json_out, indent = 4)\n",
    "\n",
    "#         f.close()\n",
    "#         json_out.close()\n",
    "\n",
    "\n",
    "def create_files_dot_json(comp_dir):\n",
    "    \n",
    "    comp_name = string.split(comp_dir,'/')[-1]\n",
    "    cfg_name = [comp_name.title() + '.cfg.in']\n",
    "\n",
    "    filesjson_out = open(comp_dir + '/db/files.json','w')\n",
    "    json.dump(cfg_name, filesjson_out)\n",
    "    filesjson_out.close()\n",
    "\n",
    "\n",
    "# def create_argv_dot_json(comp_dir):\n",
    "    \n",
    "#     comp_name = string.split(comp_dir,'/')[-1]\n",
    "#     argv = '[\"' + comp_name + '\"]'\n",
    "#     o = open(comp_dir + '/db/argv.json', 'w')\n",
    "#     o.write(argv)\n",
    "#     o.close()\n",
    "\n",
    "\n",
    "# def create_provides_dot_json(comp_dir, prov):\n",
    "#     # where prov is a list of dictionaries of the connections it provides\n",
    "    \n",
    "#     o = open(comp_dir + '/db/provides.json', 'w')\n",
    "#     json.dump(prov, o, indent = 2, sort_keys = True)\n",
    "#     o.close()\n",
    "    \n",
    "\n",
    "# def create_uses_dot_json(comp_dir, uses):\n",
    "#     # where uses is a list of dictionaries of the connections it needs\n",
    "    \n",
    "#     o = open(comp_dir + '/db/uses.json', 'w')\n",
    "#     json.dump(uses, o, indent = 2, sort_keys = True)\n",
    "#     o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_cfg_file(comp_dir):\n",
    "\n",
    "    comp_name = string.split(comp_dir,'/')[-1]\n",
    "    cfg_name = comp_name.title() + '.cfg.in'\n",
    "    cfg_file = comp_dir + '/files/' + cfg_name\n",
    "    \n",
    "    print cfg_file\n",
    "\n",
    "    # open parameters.json\n",
    "    p = open(comp_dir + '/db/parameters.json')\n",
    "    allparams = json.load(p, object_pairs_hook = OrderedDict)\n",
    "\n",
    "    # header\n",
    "    head = ['#' + 79*'=', '# Topoflow Config File for: ' + comp_name]\n",
    "\n",
    "    tablestr = head\n",
    "\n",
    "    for k in allparams.keys():\n",
    "\n",
    "        header = ['#' + 79*'=', '# ' + str(k)]\n",
    "\n",
    "        params = allparams[k]\n",
    "\n",
    "        # table\n",
    "        col1 = [str(obj['key']) for obj in params]\n",
    "        col2 = [str('{' + obj['key'] + '}') for obj in params]\n",
    "        col3 = [str(obj['value']['type']) for obj in params]\n",
    "        col4 = [str(obj['description']) + ' [' + str(obj['value']['units']) + ']' for obj in params]\n",
    "        col5 = [str(' {' + '; '.join(obj['value']['choices']) + '}') if obj['value'].has_key('choices') else '' for obj in params]\n",
    "\n",
    "        table = ['{0:20}| {1:20}| {2:10}| {3}{4}'.format(col1[i],col2[i],col3[i],col4[i],col5[i]) for i in range(len(col1))]\n",
    "        tablestr = tablestr + header + table\n",
    "\n",
    "\n",
    "    tablestr = '\\n'.join(tablestr)\n",
    "\n",
    "    cfgfile_out = open(cfg_file, 'w')\n",
    "    cfgfile_out.write(tablestr)\n",
    "    cfgfile_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_info_dot_json(comp_dir):\n",
    "    \n",
    "    comp_name = string.split(comp_dir,'/')[-1]\n",
    "\n",
    "    # open parameters.json\n",
    "    p = open(comp_dir + '/db/parameters.json')\n",
    "    params = json.load(p)\n",
    "    params = [item for it in params.values() for item in it]\n",
    "\n",
    "    info = UnsortableOrderedDict()\n",
    "\n",
    "    info['id'] = comp_name\n",
    "    info['name'] = [str(i['value']['default']) for i in params if i['key'] == 'ModelName'][0]\n",
    "    info['class'] = string.capitalize(comp_name)\n",
    "    info['initialize_args'] = comp_name + '.cfg'\n",
    "    try: info['time_step'] = [str(i['value']['default']) for i in params if i['key'] == 'dt'][0]\n",
    "    except: info['time_step'] = ''\n",
    "    info['summary'] = ''\n",
    "    info['url'] = [str(i['value']['default']) for i in params if i['key'] == 'HTML_HELP_FILE'][0]\n",
    "    info['author'] = [str(i['value']['default']) for i in params if i['key'] == 'ModelAuthor'][0]\n",
    "    info['email'] = ''\n",
    "    info['version'] = ''\n",
    "    info['doi'] = ''\n",
    "    info['license'] = ''\n",
    "    \n",
    "    try:\n",
    "        extra = read_extra_info()\n",
    "        if len(extra)>0:\n",
    "            for k in extra.keys():\n",
    "                info[k] = extra[k]\n",
    "    except: pass\n",
    "    \n",
    "    o = open(comp_dir + '/db/info.json', 'w')\n",
    "    json.dump(info, o, indent = 2)\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_extra_info():\n",
    "\n",
    "    itemFile = 'info.txt'\n",
    "    extra_info = UnsortableOrderedDict()\n",
    "\n",
    "    o = open(itemFile, mode = 'r')    \n",
    "    for line in o:\n",
    "        line = re.sub('\\n$','',line)\n",
    "        ln = re.split('\\s*[\\:\\=]\\s*', line)\n",
    "\n",
    "        error_message = 'The file ' + itemFile + ' cannot be read. Please use the format key : value'\n",
    "        assert len(ln) == 2, error_message\n",
    "\n",
    "        extra_info[str(ln[0])] = str(ln[1])\n",
    "        \n",
    "    o.close()\n",
    "\n",
    "    return extra_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating component for channels_diffusive_wave\n",
      "../../cloned_repos/component_metadata/channels_diffusive_wave/files/Channels_Diffusive_Wave.cfg.in\n",
      "Creating component for channels_dynamic_wave\n",
      "../../cloned_repos/component_metadata/channels_dynamic_wave/files/Channels_Dynamic_Wave.cfg.in\n",
      "Creating component for channels_kinematic_wave\n",
      "../../cloned_repos/component_metadata/channels_kinematic_wave/files/Channels_Kinematic_Wave.cfg.in\n",
      "Creating component for data_his\n",
      "../../cloned_repos/component_metadata/data_his/files/Data_His.cfg.in\n",
      "Creating component for diversions_fraction_method\n",
      "../../cloned_repos/component_metadata/diversions_fraction_method/files/Diversions_Fraction_Method.cfg.in\n",
      "Creating component for diversions_standard\n",
      "../../cloned_repos/component_metadata/diversions_standard/files/Diversions_Standard.cfg.in\n",
      "Creating component for evap_energy_balance\n",
      "../../cloned_repos/component_metadata/evap_energy_balance/files/Evap_Energy_Balance.cfg.in\n",
      "Creating component for evap_priestley_taylor\n",
      "../../cloned_repos/component_metadata/evap_priestley_taylor/files/Evap_Priestley_Taylor.cfg.in\n",
      "Creating component for evap_read_file\n",
      "../../cloned_repos/component_metadata/evap_read_file/files/Evap_Read_File.cfg.in\n",
      "Creating component for ice_gc2d\n",
      "../../cloned_repos/component_metadata/ice_gc2d/files/Ice_Gc2D.cfg.in\n",
      "Creating component for infil_beven\n",
      "../../cloned_repos/component_metadata/infil_beven/files/Infil_Beven.cfg.in\n",
      "Creating component for infil_green_ampt\n",
      "../../cloned_repos/component_metadata/infil_green_ampt/files/Infil_Green_Ampt.cfg.in\n",
      "Creating component for infil_richards_1d\n",
      "../../cloned_repos/component_metadata/infil_richards_1d/files/Infil_Richards_1D.cfg.in\n",
      "Creating component for infil_smith_parlange\n",
      "../../cloned_repos/component_metadata/infil_smith_parlange/files/Infil_Smith_Parlange.cfg.in\n",
      "Creating component for meteorology\n",
      "../../cloned_repos/component_metadata/meteorology/files/Meteorology.cfg.in\n",
      "Creating component for satzone_darcy_layers\n",
      "../../cloned_repos/component_metadata/satzone_darcy_layers/files/Satzone_Darcy_Layers.cfg.in\n",
      "Creating component for snow_degree_day\n",
      "../../cloned_repos/component_metadata/snow_degree_day/files/Snow_Degree_Day.cfg.in\n",
      "Creating component for snow_energy_balance\n",
      "../../cloned_repos/component_metadata/snow_energy_balance/files/Snow_Energy_Balance.cfg.in\n",
      "Creating component for testservice\n",
      "../../cloned_repos/component_metadata/testservice/files/Testservice.cfg.in\n",
      "Creating component for topoflow\n",
      "../../cloned_repos/component_metadata/topoflow/files/Topoflow.cfg.in\n"
     ]
    }
   ],
   "source": [
    "yaml_root = 'yaml/'\n",
    "components_root = '../../cloned_repos/component_metadata/'\n",
    "\n",
    "yaml_dirs = glob.iglob(yaml_root + '*') # xml files\n",
    "\n",
    "for comp in yaml_dirs:\n",
    "    \n",
    "    comp_name = string.split(comp,'/')[-1]\n",
    "    \n",
    "    print 'Creating component for ' + comp_name\n",
    "    \n",
    "    # make new dirs\n",
    "    comp_dir = components_root + string.lower(comp_name)\n",
    "#     if not os.path.exists(comp_dir):\n",
    "#         os.makedirs(comp_dir)\n",
    "#         os.makedirs(comp_dir + '/db')\n",
    "#         os.makedirs(comp_dir + '/files')\n",
    "    \n",
    "#     # copy yaml file to new component dir structure\n",
    "#     shutil.copyfile(comp + '/parameters.yaml', comp_dir + '/db/parameters.yaml')\n",
    "    \n",
    "#     # make a json parameter file\n",
    "#     yaml_to_json(comp_dir)\n",
    "    \n",
    "    # files.json\n",
    "    create_files_dot_json(comp_dir)\n",
    "    \n",
    "#     # argv.json -> name of the component\n",
    "#     create_argv_dot_json(comp_dir)\n",
    "    \n",
    "#     # info.json\n",
    "#     create_info_dot_json(comp_dir)\n",
    "    \n",
    "#     # provides.json\n",
    "#     provides = [{'id':str(comp_name),'required':False}]\n",
    "#     create_provides_dot_json(comp_dir, provides)\n",
    "    \n",
    "#     # uses.json\n",
    "#     uses = [{'id':'----','required':False}]\n",
    "#     create_uses_dot_json(comp_dir, uses)\n",
    "    \n",
    "    # cfg.in file\n",
    "    create_cfg_file(comp_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The_Brown_Fox'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'the_brown_fox'.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
