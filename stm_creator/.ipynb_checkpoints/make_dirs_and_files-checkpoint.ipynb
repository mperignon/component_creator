{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob, string, os, re\n",
    "\n",
    "import yaml, json\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "\n",
    "class UnsortableList(list):\n",
    "    def sort(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "class UnsortableOrderedDict(OrderedDict):\n",
    "    def items(self, *args, **kwargs):\n",
    "        return UnsortableList(OrderedDict.items(self, *args, **kwargs))\n",
    "\n",
    "\n",
    "class OrderedDictYAMLLoader(yaml.Loader):\n",
    "    \"\"\"\n",
    "    A YAML loader that loads mappings into ordered dictionaries.\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        yaml.Loader.__init__(self, *args, **kwargs)\n",
    " \n",
    "        self.add_constructor(u'tag:yaml.org,2002:map', type(self).construct_yaml_map)\n",
    "        self.add_constructor(u'tag:yaml.org,2002:omap', type(self).construct_yaml_map)\n",
    " \n",
    "    def construct_yaml_map(self, node):\n",
    "        data = OrderedDict()\n",
    "        yield data\n",
    "        value = self.construct_mapping(node)\n",
    "        data.update(value)\n",
    " \n",
    "    def construct_mapping(self, node, deep=False):\n",
    "        if isinstance(node, yaml.MappingNode):\n",
    "            self.flatten_mapping(node)\n",
    "        else:\n",
    "            raise yaml.constructor.ConstructorError(None, None,\n",
    "                'expected a mapping node, but found %s' % node.id, node.start_mark)\n",
    " \n",
    "        mapping = OrderedDict()\n",
    "        for key_node, value_node in node.value:\n",
    "            key = self.construct_object(key_node, deep=deep)\n",
    "            try:\n",
    "                hash(key)\n",
    "            except TypeError, exc:\n",
    "                raise yaml.constructor.ConstructorError('while constructing a mapping',\n",
    "                    node.start_mark, 'found unacceptable key (%s)' % exc, key_node.start_mark)\n",
    "            value = self.construct_object(value_node, deep=deep)\n",
    "            mapping[key] = value\n",
    "        return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_argv_dot_json(comp_dir):\n",
    "    \n",
    "    comp_name = string.split(comp_dir,'/')[-1]\n",
    "    argv = '[\"' + comp_name + '\"]'\n",
    "    o = open(comp_dir + '/db/argv.json', 'w')\n",
    "    o.write(argv)\n",
    "    o.close()\n",
    "    \n",
    "def create_provides_dot_json(comp_dir):\n",
    "    \n",
    "    comp_name = string.split(comp_dir,'/')[-1]\n",
    "    argv = '[\"' + comp_name + '\"]'\n",
    "    o = open(comp_dir + '/db/provides.json', 'w')\n",
    "    o.write(argv)\n",
    "    o.close()\n",
    "    \n",
    "def create_uses_dot_json(comp_dir):\n",
    "    \n",
    "    comp_name = string.split(comp_dir,'/')[-1]\n",
    "    argv = '[\"' + comp_name + '\"]'\n",
    "    o = open(comp_dir + '/db/uses.json', 'w')\n",
    "    o.write(argv)\n",
    "    o.close()\n",
    "    \n",
    "def create_files_dot_json(comp_dir):\n",
    "    \n",
    "    comp_name = string.split(comp_dir,'/')[-1]\n",
    "    cfg_name = comp_name + '.cfg.in'\n",
    "\n",
    "    filesjson_out = open(comp_dir + '/db/files.json','w')\n",
    "    json.dump([cfg_name], filesjson_out)\n",
    "    filesjson_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_extra_info():\n",
    "\n",
    "    itemFile = 'info.txt'\n",
    "    extra_info = UnsortableOrderedDict()\n",
    "\n",
    "    o = open(itemFile, mode = 'r')    \n",
    "    for line in o:\n",
    "        line = re.sub('\\n$','',line)\n",
    "        ln = re.split('\\s*[\\:\\=]\\s*', line)\n",
    "\n",
    "        error_message = 'The file ' + itemFile + ' cannot be read. Please use the format key : value'\n",
    "        assert len(ln) == 2, error_message\n",
    "\n",
    "        extra_info[str(ln[0])] = str(ln[1])\n",
    "        \n",
    "    o.close()\n",
    "\n",
    "    return extra_info\n",
    "\n",
    "def create_info_dot_json(comp_dir):\n",
    "    \n",
    "    comp_name = string.split(comp_dir,'/')[-1]\n",
    "\n",
    "    info = UnsortableOrderedDict()\n",
    "\n",
    "    info['id'] = comp_name\n",
    "    info['name'] = comp_name\n",
    "    info['class'] = comp_name\n",
    "    info['initialize_args'] = comp_name + '.cfg'\n",
    "    info['time_step'] = ''\n",
    "    info['summary'] = ''\n",
    "    info['url'] = \"http://csdms.colorado.edu/wiki/Model_help:\" + comp_name\n",
    "    info['author'] = ''\n",
    "    info['email'] = ''\n",
    "    info['version'] = ''\n",
    "    info['doi'] = ''\n",
    "    info['license'] = ''\n",
    "\n",
    "    extra = read_extra_info()\n",
    "    if len(extra)>0:\n",
    "        for k in extra.keys():\n",
    "            info[k] = extra[k]\n",
    "\n",
    "    o = open(comp_dir + '/db/info.json', 'w')\n",
    "    json.dump(info, o, indent = 2)\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parameters_dot_json(code_root,comp_name):\n",
    "\n",
    "    with open(code_root + '/' + comp_name + '/Initialize.c') as p:\n",
    "        k = p.read()\n",
    "\n",
    "    k = re.sub('\\n',' ',k)\n",
    "    m = re.search('int Initialize\\((.*?)\\)', k)\n",
    "    m = m.group(0)\n",
    "\n",
    "    m = re.sub('int Initialize\\(','',m)\n",
    "    m = re.sub('\\)','',m)\n",
    "    m = re.sub('\\*','',m)\n",
    "    m = re.sub('\\s{2}','',m)\n",
    "    m = re.sub('double','float',m)\n",
    "\n",
    "    m_ = m.split(', ')\n",
    "    m_ = [m.split(' ') for m in m_]\n",
    "\n",
    "    out_key = [m[1] for m in m_]\n",
    "    out_type = [m[0] for m in m_]\n",
    "\n",
    "with open(code_root + '/' + comp_name + '/Key for Inputs.txt') as p:\n",
    "    k = p.read()\n",
    "keys_in = k.split('\\n')\n",
    "\n",
    "kin = [k.split('   ') for k in keys_in]\n",
    "\n",
    "kin = [k for k in kin if len(k)==2]\n",
    "\n",
    "out_key_file = [k[0] for k in kin]\n",
    "out_desc = [k[1] for k in kin]\n",
    "\n",
    "for i in range(len(out_desc)):\n",
    "\n",
    "    u = re.search('\\[.{1,6}\\]',out_desc[i])\n",
    "\n",
    "    if u:\n",
    "        out_units.append(u.group(0))\n",
    "        out_desc[i] = re.sub(' \\[.{1,6}\\]','',out_desc[i])\n",
    "    else:\n",
    "        out_units.append('-')\n",
    "\n",
    "keys = ['key', 'name', 'description', 'value']\n",
    "\n",
    "out_all = []\n",
    "    \n",
    "    if len(out_key) == len(out_key_file):\n",
    "\n",
    "        for i in range(len(out_key)):\n",
    "\n",
    "            val = OrderedDict()\n",
    "            val['type'] = out_type[i]\n",
    "            val['units'] = out_units[i]\n",
    "\n",
    "            out_obj = OrderedDict()\n",
    "            pairs = zip(keys,[out_key[i],out_key[i],out_desc[i],val])\n",
    "\n",
    "            for key, value in pairs:\n",
    "                out_obj[key] = value\n",
    "\n",
    "            out_all.append(out_obj)\n",
    "\n",
    "        outFile = comp_dir + '/db/parameters.json'\n",
    "        json_out = open(outFile,'w')\n",
    "        json.dump(out_all, json_out, indent = 4)\n",
    "\n",
    "        json_out.close()\n",
    "                    \n",
    "    else:\n",
    "        print 'not the same length! Input', comp_name      \n",
    "        \n",
    "        \n",
    "def parameters_out_dot_json(code_root,comp_name):\n",
    "\n",
    "    with open(code_root + '/' + comp_name + '/Finalize.c') as p:\n",
    "        k = p.read()\n",
    "\n",
    "    k = re.sub('\\n',' ',k)\n",
    "    m = re.search('int Finalize\\((.*?)\\)', k)\n",
    "    m = m.group(0)\n",
    "\n",
    "    m = re.sub('int Finalize\\(','',m)\n",
    "    m = re.sub('\\)','',m)\n",
    "    m = re.sub('\\[\\]','',m)\n",
    "    m = re.sub('\\s{2}','',m)\n",
    "    m = re.sub('double','float',m)\n",
    "\n",
    "    m_ = m.split(', ')\n",
    "    m_ = [m.split(' ') for m in m_]\n",
    "\n",
    "    out_key = [m[1] for m in m_]\n",
    "    out_type = [m[0] for m in m_]\n",
    "\n",
    "\n",
    "\n",
    "    with open(code_root + '/' + comp_name + '/Key for Outputs.txt') as p:\n",
    "        k = p.read()\n",
    "\n",
    "    k = re.sub('\\t','@',k)\n",
    "\n",
    "    keys_in = k.split('\\n')\n",
    "    keys_in = keys_in[1:]\n",
    "\n",
    "    keys_in = [k for k in keys_in if len(k)>1]\n",
    "\n",
    "    kin = [k.split('@') for k in keys_in]\n",
    "    kin_ = [[k_ for k_ in k if len(k_)>0] for k in kin]\n",
    "\n",
    "    out_key_file = [re.sub('\\s','',k[0]) for k in kin_]\n",
    "    out_desc = [k[1] for k in kin_]\n",
    "    out_units = []\n",
    "\n",
    "    for i in range(len(out_desc)):\n",
    "\n",
    "        u = re.search('\\[.{1,6}\\]',out_desc[i])\n",
    "\n",
    "        if u:\n",
    "            out_units.append(u.group(0))\n",
    "            out_desc[i] = re.sub(' \\[.{1,6}\\]','',out_desc[i])\n",
    "        else:\n",
    "            out_units.append('-')\n",
    "\n",
    "\n",
    "    keys = ['key', 'name', 'description', 'value']\n",
    "\n",
    "    out_all = []\n",
    "\n",
    "    if len(out_key) == len(out_key_file):\n",
    "\n",
    "        for i in range(len(out_key)):\n",
    "\n",
    "            val = OrderedDict()\n",
    "            val['type'] = out_type[i]\n",
    "            val['units'] = out_units[i]\n",
    "\n",
    "            out_obj = OrderedDict()\n",
    "            pairs = zip(keys,[out_key[i],out_key[i],out_desc[i],val])\n",
    "\n",
    "            for key, value in pairs:\n",
    "                out_obj[key] = value\n",
    "\n",
    "            out_all.append(out_obj)\n",
    "\n",
    "        outFile = comp_dir + '/db/parameters_out.json'\n",
    "        json_out = open(outFile,'w')\n",
    "        json.dump(out_all, json_out, indent = 4)\n",
    "\n",
    "        json_out.close()\n",
    "\n",
    "    else:\n",
    "        print 'not the same length! Output', comp_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_cfg_file(comp_dir, code_root):\n",
    "\n",
    "    comp_name = string.split(comp_dir,'/')[-1]\n",
    "    cfg_name = comp_name + '.cfg.in'\n",
    "    cfg_file = comp_dir + '/files/' + cfg_name\n",
    "\n",
    "    # header\n",
    "    head = ['#' + 79*'=', '# STM Config File for: ' + comp_name]\n",
    "    tablestr = head\n",
    "\n",
    "    try:\n",
    "        # open Key files - input\n",
    "        with open(code_root + '/' + comp_name + '/Key for Inputs.txt') as p:\n",
    "            k = p.read()\n",
    "        keys_in = k.split('\\n')\n",
    "\n",
    "        header = ['#' + 79*'=', '# Input']\n",
    "        tablestr = tablestr + header\n",
    "\n",
    "        for k in keys_in:\n",
    "\n",
    "            k_ = k.split('   ')\n",
    "            \n",
    "            if len(k_) == 2:\n",
    "\n",
    "                col1 = k_[0]\n",
    "                col2 = '{' + k_[0] + '}'\n",
    "                col3 = 'float'\n",
    "                col4 = k_[1].capitalize()\n",
    "                col5 = ' [-]' if not '[' in k_[1] else ''\n",
    "\n",
    "                table = ['{0:20}| {1:20}| {2:10}| {3}{4}'.format(col1,col2,col3,col4,col5)]\n",
    "\n",
    "                tablestr = tablestr + table\n",
    "\n",
    "    except:\n",
    "        print '%%%%Problem in ' + comp_name + ' Input'\n",
    "\n",
    "    try:\n",
    "        # open Key files - output\n",
    "        with open(code_root + '/' + comp_name + '/Key for Outputs.txt') as p:\n",
    "            k = p.read()\n",
    "        keys_in = k.split('\\n')\n",
    "        keys_in = keys_in[1:]\n",
    "\n",
    "        header = ['#' + 79*'=', '# Output']\n",
    "        tablestr = tablestr + header\n",
    "\n",
    "        for k in keys_in:\n",
    "\n",
    "            if len(k)>0:\n",
    "\n",
    "                k_ = re.split('\\t*',k)\n",
    "                \n",
    "                if len(k_) == 2:\n",
    "\n",
    "                    k_[0] = re.sub('\\s*','',k_[0])\n",
    "\n",
    "                    col1 = k_[0]\n",
    "                    col2 = '{' + k_[0] + '}'\n",
    "                    col3 = 'float'\n",
    "                    col4 = k_[1].capitalize()\n",
    "                    col5 = ' [-]' if not '[' in k_[1] else ''\n",
    "\n",
    "                    table = ['{0:20}| {1:20}| {2:10}| {3}{4}'.format(col1,col2,col3,col4,col5)]\n",
    "\n",
    "                    tablestr = tablestr + table\n",
    "    except:\n",
    "        print '%%%%Problem in ' + comp_name + ' Output'\n",
    "\n",
    "    tablestr = '\\n'.join(tablestr)\n",
    "\n",
    "    cfgfile_out = open(cfg_file, 'w')\n",
    "    cfgfile_out.write(tablestr)\n",
    "    cfgfile_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not the same length! Input 1DDeltaBW\n",
      "not the same length! Output 1DDeltaBW\n",
      "not the same length! Input 1DDeltaNorm\n",
      "not the same length! Output 1DDeltaNorm\n",
      "not the same length! Input 1DRiverWFRisingBaseLevelNormal\n",
      "not the same length! Output 1DRiverWFRisingBaseLevelNormal\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-365-44fc3defaee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#     create_cfg_file(comp_dir, code_root)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mparameters_dot_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_root\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mparameters_out_dot_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_root\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcomp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-363-9762eec1fafa>\u001b[0m in \u001b[0;36mparameters_dot_json\u001b[0;34m(code_root, comp_name)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mkin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'   '\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mout_key_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mkin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'['\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mout_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "code_root = '../../stm/'\n",
    "components_root = 'components/'\n",
    "\n",
    "code_dirs = glob.iglob(code_root + '*') # original code\n",
    "\n",
    "for comp in code_dirs:\n",
    "    \n",
    "    comp_name = string.split(comp,'/')[-1]\n",
    "    comp_name = comp_name.replace(\" \",\"\")\n",
    "    \n",
    "#     print 'Creating component for ' + comp_name\n",
    "    \n",
    "    # make new dirs\n",
    "    comp_dir = components_root + comp_name\n",
    "    if not os.path.exists(comp_dir):\n",
    "        os.makedirs(comp_dir)\n",
    "        os.makedirs(comp_dir + '/db')\n",
    "        os.makedirs(comp_dir + '/files')\n",
    "        \n",
    "    # make a json parameter file\n",
    "    \n",
    "    # files.json\n",
    "#     create_files_dot_json(comp_dir)\n",
    "    \n",
    "    # argv.json -> name of the component\n",
    "#     create_argv_dot_json(comp_dir)\n",
    "    \n",
    "    # info.json\n",
    "#     create_info_dot_json(comp_dir)\n",
    "    \n",
    "    # provides.json - empty?\n",
    "#     create_provides_dot_json(comp_dir)\n",
    "    \n",
    "    # uses.json - empty?\n",
    "#     create_uses_dot_json(comp_dir)\n",
    "    \n",
    "    # cfg.in file\n",
    "#     create_cfg_file(comp_dir, code_root)\n",
    "\n",
    "    parameters_dot_json(code_root,comp_name)\n",
    "    parameters_out_dot_json(code_root,comp_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not the same length! Input Acronym1\n"
     ]
    }
   ],
   "source": [
    "with open(code_root + '/' + comp_name + '/Initialize.c') as p:\n",
    "    k = p.read()\n",
    "\n",
    "k = re.sub('\\n',' ',k)\n",
    "m = re.search('int Initialize\\((.*?)\\)', k)\n",
    "m = m.group(0)\n",
    "\n",
    "m = re.sub('int Initialize\\(','',m)\n",
    "m = re.sub('\\)','',m)\n",
    "m = re.sub('\\*','',m)\n",
    "m = re.sub('\\s{2}','',m)\n",
    "m = re.sub('double','float',m)\n",
    "m = re.sub('\\[\\]','',m)\n",
    "\n",
    "m_ = m.split(', ')\n",
    "m_ = [m.split(' ') for m in m_]\n",
    "\n",
    "out_key = [m[1] for m in m_]\n",
    "out_type = [m[0] for m in m_]\n",
    "\n",
    "with open(code_root + '/' + comp_name + '/Key for Inputs.txt') as p:\n",
    "    k = p.read()\n",
    "keys_in = k.split('\\n')\n",
    "\n",
    "kin = [k.split('   ') for k in keys_in]\n",
    "\n",
    "kin = [k for k in kin if len(k)==2]\n",
    "\n",
    "out_key_file = [k[0] for k in kin]\n",
    "out_desc = [k[1] for k in kin]\n",
    "\n",
    "for i in range(len(out_desc)):\n",
    "\n",
    "    u = re.search('\\[.{1,6}\\]',out_desc[i])\n",
    "\n",
    "    if u:\n",
    "        out_units.append(u.group(0))\n",
    "        out_desc[i] = re.sub(' \\[.{1,6}\\]','',out_desc[i])\n",
    "    else:\n",
    "        out_units.append('-')\n",
    "\n",
    "keys = ['key', 'name', 'description', 'value']\n",
    "\n",
    "out_all = []\n",
    "\n",
    "if len(out_key) == len(out_key_file):\n",
    "\n",
    "    for i in range(len(out_key)):\n",
    "\n",
    "        val = OrderedDict()\n",
    "        val['type'] = out_type[i]\n",
    "        val['units'] = out_units[i]\n",
    "\n",
    "        out_obj = OrderedDict()\n",
    "        pairs = zip(keys,[out_key[i],out_key[i],out_desc[i],val])\n",
    "\n",
    "        for key, value in pairs:\n",
    "            out_obj[key] = value\n",
    "\n",
    "        out_all.append(out_obj)\n",
    "\n",
    "    outFile = comp_dir + '/db/parameters.json'\n",
    "    json_out = open(outFile,'w')\n",
    "    json.dump(out_all, json_out, indent = 4)\n",
    "\n",
    "    json_out.close()\n",
    "\n",
    "else:\n",
    "    print 'not the same length! Input', comp_name   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'R',\n",
       " 'ustar',\n",
       " 'npp',\n",
       " 'Dsg',\n",
       " 'Dlg',\n",
       " 'sigmasg',\n",
       " 'sigmalg',\n",
       " 'np',\n",
       " 'nppo',\n",
       " 'qb',\n",
       " 'swap',\n",
       " 'pfl',\n",
       " 'po',\n",
       " 'oo',\n",
       " 'so']"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R', 'u']"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_key_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
